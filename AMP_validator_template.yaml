AWSTemplateFormatVersion: 2010-09-09
Description: Creates a CodePipeline that automatically spins up and updates a Lambda function hosted on GitHub



Metadata:
  AWS::CloudFormation::Interface:
    ParameterGroups:
      -
        Label:
          default: "GitHub Configuration"
        Parameters:
          - GitHubOAuthToken
          - RepoOwner
          - GitHubRepo
          - GitHubBranch
      -
        Label:
          default: "Lambda Configuration"
        Parameters:
          - AppName
    ParameterLabels:
      GitHubOAuthToken:
        default: "GitHubOAuthToken"
      RepoOwner:
        default: "RepoOwner"
      GitHubRepo:
        default: "GitHubRepo"
      GitHubBranch:
        default: "GitHubBranch"
      AppName:
        default: "AppName"

Parameters:
  AppName:
    Type: String
    Default: cf-deploy
    Description: Name of the Lambda Function

  GitHubOAuthToken:
    Type: String
    NoEcho: true
    MinLength: 40
    MaxLength: 40
    Description: With this Token a Webhook will be created for the repo

  RepoOwner:
    Type: String
    AllowedPattern: "[A-Za-z0-9-]+"
    Description: The Owner of the GitHub Repo

  GitHubRepo:
    Type: String
    Description: The name of the GitHub Repo

  GitHubBranch:
    Type: String
    Default: main
    AllowedPattern: "[A-Za-z0-9-]+"
    Description: The name of the GitHub Repo Branch which should be used

Resources:

  #S3 Bucket containing the artifacts retrieved on the "Source" step of the pipeline
  ArtifactBucket:
    Type: AWS::S3::Bucket
    DeletionPolicy: Delete
    Properties:
      BucketName: !Join
      - "-"
      - - !Ref 'AWS::StackName'
        - "artifacts"
        - !Select
          - 0
          - !Split
            - "-"
            - !Select
              - 2
              - !Split
                - "/"
                - !Ref "AWS::StackId"

  #Custom resource used to link the Lambda cleanup function with the artifacts bucket
  CleanupBucketOnDelete:
    DependsOn: CleanupBucketOnDeleteLambda
    Type: Custom::cleanupbucket
    Properties:
      ServiceToken: 
       Fn::GetAtt: 
          - "CleanupBucketOnDeleteLambda"
          - "Arn"
      BucketName: !Ref ArtifactBucket

  #Lambda function that cleans up the artifacts s3 bucket files when a delete stack action is fired so the bucket can be successfully deleted.
  CleanupBucketOnDeleteLambda:
    DependsOn: ArtifactBucket
    Type: "AWS::Lambda::Function"
    Properties:
      Code:
        ZipFile: !Sub |
          #!/usr/bin/env python
          # -*- coding: utf-8 -*-
          import json
          import boto3
          import urllib3
          def empty_delete_buckets(bucket_name):
              """
              Empties and deletes the bucket
              :param bucket_name:
              :param region:
              :return:
              """
              print("trying to delete the bucket {0}".format(bucket_name))
              # s3_client = SESSION.client('s3', region_name=region)
              s3_client = boto3.client('s3')
              # s3 = SESSION.resource('s3', region_name=region)
              s3 = boto3.resource('s3')
              try:
                  bucket = s3.Bucket(bucket_name).load()
              except ClientError:
                  print("bucket {0} does not exist".format(bucket_name))
                  return
              # Check if versioning is enabled
              response = s3_client.get_bucket_versioning(Bucket=bucket_name)
              status = response.get('Status','')
              if status == 'Enabled':
                  response = s3_client.put_bucket_versioning(Bucket=bucket_name,
                                                              VersioningConfiguration={'Status': 'Suspended'})
              paginator = s3_client.get_paginator('list_object_versions')
              page_iterator = paginator.paginate(
                  Bucket=bucket_name
              )
              for page in page_iterator:
                  print(page)
                  if 'DeleteMarkers' in page:
                      delete_markers = page['DeleteMarkers']
                      if delete_markers is not None:
                          for delete_marker in delete_markers:
                              key = delete_marker['Key']
                              versionId = delete_marker['VersionId']
                              s3_client.delete_object(Bucket=bucket_name, Key=key, VersionId=versionId)
                  if 'Versions' in page and page['Versions'] is not None:
                      versions = page['Versions']
                      for version in versions:
                          print(version)
                          key = version['Key']
                          versionId = version['VersionId']
                          s3_client.delete_object(Bucket=bucket_name, Key=key, VersionId=versionId)
              object_paginator = s3_client.get_paginator('list_objects_v2')
              page_iterator = object_paginator.paginate(
                  Bucket=bucket_name
              )
              for page in page_iterator:
                  if 'Contents' in page:
                      for content in page['Contents']:
                          key = content['Key']
                          s3_client.delete_object(Bucket=bucket_name, Key=content['Key'])
              #UNCOMMENT THE LINE BELOW TO MAKE LAMBDA DELETE THE BUCKET.  
              # THIS WILL CAUSE AN FAILURE SINCE CLOUDFORMATION ALSO TRIES TO DELETE THE BUCKET
              #s3_client.delete_bucket(Bucket=bucket_name)
              #print "Successfully deleted the bucket {0}".format(bucket_name)
              print("Successfully emptied the bucket {0}".format(bucket_name))
          def lambda_handler(event, context):
              try:
                  bucket = event['ResourceProperties']['BucketName']
                  if event['RequestType'] == 'Delete':
                      empty_delete_buckets(bucket)
                      #s3 = boto3.resource('s3')
                      #bucket.objects.all().delete()
                      #bucket = s3.Bucket(bucket)
                      #for obj in bucket.objects.filter():
                          #s3.Object(bucket.name, obj.key).delete()
                  sendResponseCfn(event, context, "SUCCESS")
              except Exception as e:
                  print(e)
                  sendResponseCfn(event, context, "FAILED")
          def sendResponseCfn(event, context, responseStatus):
              http = urllib3.PoolManager()
              response_body = {'Status': responseStatus,
                              'Reason': 'Log stream name: ' + context.log_stream_name,
                              'PhysicalResourceId': context.log_stream_name,
                              'StackId': event['StackId'],
                              'RequestId': event['RequestId'],
                              'LogicalResourceId': event['LogicalResourceId'],
                              'Data': json.loads("{}")}
              http.request('PUT', event['ResponseURL'], body=json.dumps(response_body))
              #Deprecated from boto3.vendored requests
              #requests.put(event['ResponseURL'], data=json.dumps(response_body))
      Description: cleanup Bucket on Delete Lambda Lambda function.
      # FunctionName: lambda_function
      Handler: index.lambda_handler
      Role : !GetAtt CleanupBucketOnDeleteLambdaRole.Arn
      Runtime: python3.9
      Timeout: 60

  #Lambda role needed to set up the lambda dependency used for bucket cleanup
  CleanupBucketOnDeleteLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service:
            - lambda.amazonaws.com
          Action:
          - sts:AssumeRole
      Path: "/"
      Policies:
      - PolicyName: !Join [ -, [!Ref 'AWS::StackName', 'CleanupBucketOnDeleteLambdaPolicy'] ]
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action:
            - logs:*
            - s3:*
            Resource: '*'
          - Effect: Deny
            Action:
            - s3:DeleteBucket
            Resource: '*'

  #
  # Roles used to give permissions to the services that are going to interact with other services
  #
  CodeBuildServiceRole:
    Type: AWS::IAM::Role
    Properties:
      Path: /
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: codebuild.amazonaws.com
            Action: sts:AssumeRole
      Policies:
        - PolicyName: root
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Resource: "*"
                Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                  - cloudformation:*
                  - iam:*
                  - lambda:*
                  - ssm:*
                  - apigateway:*
                  - codepipeline:*
                  - codebuild:*
              - Resource: !Sub arn:aws:s3:::${ArtifactBucket}/*
                Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:PutObject
                  - s3:GetObjectVersion


  CodePipelineServiceRole:
    Type: AWS::IAM::Role
    Properties:
      Path: /
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - codepipeline.amazonaws.com
                - cloudformation.amazonaws.com
            Action: sts:AssumeRole
      Policies:
        - PolicyName: root
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Resource:
                  - !Sub arn:aws:s3:::${ArtifactBucket}/*
                Effect: Allow
                Action:
                  - s3:PutObject
                  - s3:GetObject
                  - s3:GetObjectVersion
                  - s3:GetBucketVersioning
              - Resource: "*"
                Effect: Allow
                Action:
                  - codebuild:StartBuild
                  - codebuild:BatchGetBuilds
                  - cloudformation:*
                  - iam:*
                  - lambda:*
                  - ssm:*
                  - apigateway:*
                  - codepipeline:*
                  - codebuild:*
                  - sts:AssumeRole
                  - codecommit:*

  # Code Build Project used to package the lambda function and make the AWS SAM Template ready to be processed by CloudFormation
  CodeBuildProject:
    Type: AWS::CodeBuild::Project
    Properties:
      Artifacts:
        Type: CODEPIPELINE
      Source:
        Type: CODEPIPELINE
      Environment:
        ComputeType: BUILD_GENERAL1_SMALL
        Image: aws/codebuild/amazonlinux2-x86_64-standard:3.0
        Type: LINUX_CONTAINER
        # This variables will be used by buildspec.yaml file
        EnvironmentVariables:
          - Name: S3Bucket
            Value: !Ref ArtifactBucket
          - Name: APP_NAME
            Value: !Ref AppName
      Name: !Ref AWS::StackName
      ServiceRole: !Ref CodeBuildServiceRole

  
  Pipeline:
    Type: AWS::CodePipeline::Pipeline
    Properties:
      RoleArn: !GetAtt CodePipelineServiceRole.Arn
      ArtifactStore:
        Type: S3
        Location: !Ref ArtifactBucket
      Stages:
        - Name: Source
          Actions:
            # Source stage: Gets all the code from the previously specified GitHub repository 
            # and zips all the files as one Output Artifact to use it as an input artifact on the next step.
            - Name: Source
              ActionTypeId:
                Category: Source
                Owner: ThirdParty
                Version: "1"
                Provider: GitHub
              Configuration:
                Owner: !Ref RepoOwner
                Repo: !Ref GitHubRepo
                Branch: !Ref GitHubBranch
                PollForSourceChanges: true
                OAuthToken: !Ref GitHubOAuthToken
              OutputArtifacts:
                - Name: SourceCode
              RunOrder: 1
        
        #Build stage: Packages the SAM template named template.yaml to transform it into a processable CloudFormation template (package.yaml)
        - Name: Build
          Actions:
            - Name: Build
              ActionTypeId:
                Category: Build
                Owner: AWS
                Version: "1"
                Provider: CodeBuild
              Configuration:
                ProjectName: !Ref CodeBuildProject
              InputArtifacts:
                - Name: SourceCode
              OutputArtifacts:
                - Name: BuildOutput
              RunOrder: 1

        #Deploy Stage: Uses the CloudFormation ChangeSet action to update the CloudFormation stack and deploy it, it creates a new version of the lambda function
        - Name: Deploy
          Actions:
            - Name: CreateChangeSet
              ActionTypeId:
                Category: Deploy
                Owner: AWS
                Version: "1"
                Provider: CloudFormation
              Configuration:
                ChangeSetName: update
                ActionMode: CHANGE_SET_REPLACE
                StackName: !Ref AppName
                RoleArn: !GetAtt CodePipelineServiceRole.Arn
                Capabilities: CAPABILITY_NAMED_IAM
                TemplatePath: BuildOutput::package.yaml
              InputArtifacts:
                - Name: BuildOutput
              RunOrder: 1
            - Name: DeployChangeSet
              ActionTypeId:
                Category: Deploy
                Owner: AWS
                Version: "1"
                Provider: CloudFormation
              Configuration:
                ChangeSetName: update
                ActionMode: CHANGE_SET_EXECUTE
                StackName: !Ref AppName
                RoleArn: !GetAtt CodePipelineServiceRole.Arn
              InputArtifacts:
                - Name: BuildOutput
              RunOrder: 2

Outputs:
  PipelineUrl:
    Value: !Sub https://console.aws.amazon.com/codepipeline/home?region=${AWS::Region}#/view/${Pipeline}